{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Dataset.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Importing, Normalization and Data Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data in csv\n",
    "\n",
    "diabetes_df = pd.read_csv(\"Datasets/diabetes-data.txt\",delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Diabetes Dataset Attribute: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving column Names as discussed in dataset description file\n",
    "\n",
    "diabetes_df.columns = [\n",
    "                        'PregnantTimes',\n",
    "                        'PlasmaGlucose',\n",
    "                        'DiastolicBlood',\n",
    "                        'TricepsSkinFold',\n",
    "                        'SerumInsulin',\n",
    "                        'BMI',\n",
    "                        'DiabetesPedigree',\n",
    "                        'Age',\n",
    "                        'Class'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viwing first 10 rows\n",
    "\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the shape of matrix \n",
    "\n",
    "diabetes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repacing the '?' with Nan Values \n",
    "\n",
    "diabetes_df.replace(\"?\", np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the null values of each column\n",
    "\n",
    "diabetes_df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Null values in each column\n",
    "\n",
    "diabetes_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types of each column of dataset\n",
    "\n",
    "diabetes_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many object(str) types converting them into float\n",
    "\n",
    "diabetes_df = diabetes_df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the Nan values with Mean becuase droping columns will reduce the size of dataset and will cause underfitting\n",
    "\n",
    "diabetes_df = diabetes_df.fillna(diabetes_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varifying if all the Values Have been filled\n",
    "\n",
    "diabetes_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking again the types to varify whether type is changed or not\n",
    "\n",
    "diabetes_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting output label back to int for only (0 or 1 values)\n",
    "\n",
    "diabetes_df['Class'] = diabetes_df['Class'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics to know about Data minimum, maximum and Standard Deviation before selecting any feature\n",
    "\n",
    "diabetes_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Deviation of some of values is very high and showing bad behavior about data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how many columns have 0 values in dataset\n",
    "\n",
    "diabetes_df.isin({0.0}).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all columns wiht mean expect pregnantTimes becuase there are some cases when patient has diabeties and hasn't been prgnent yet\n",
    "\n",
    "diabetes_df['PlasmaGlucose'] = diabetes_df['PlasmaGlucose'].replace(0.0,diabetes_df['PlasmaGlucose'].mean())\n",
    "diabetes_df['DiastolicBlood']=diabetes_df['DiastolicBlood'].replace(0.0,diabetes_df['DiastolicBlood'].mean())\n",
    "diabetes_df['TricepsSkinFold']=diabetes_df['TricepsSkinFold'].replace(0.0,diabetes_df['TricepsSkinFold'].mean())\n",
    "diabetes_df['SerumInsulin']=diabetes_df['SerumInsulin'].replace(0.0,diabetes_df['SerumInsulin'].mean())\n",
    "diabetes_df['BMI']=diabetes_df['BMI'].replace(0.0,diabetes_df['BMI'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the 0's again in each column\n",
    "\n",
    "diabetes_df.isin({0.0}).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting all the features for our X values except label column and first we will predicit on it\n",
    "\n",
    "X = diabetes_df.iloc[:, [0,1,2,3,4,5,6,7]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperory Variable feature\n",
    "\n",
    "Feature = X\n",
    "Feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our Target output y\n",
    "\n",
    "y = diabetes_df['Class'].values\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking again the summary statistics. Our data is much better now\n",
    "\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the Dataset into a fix range of values \n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset using Scikit learning in 75 and 25 ratio for train and test respectivly\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.25, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pridicting the dataset on different values of K from 1 to 20\n",
    "\n",
    "k = 1\n",
    "for i in range (20):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k).fit(X_train,Y_train)\n",
    "    yhat = knn.predict(X_test)\n",
    "    print (\"KNN With k = \" + str(k))\n",
    "    print(\"Accuracy on train data with k = \" + str (k) + \" : \", metrics.accuracy_score(Y_train,knn.predict(X_train)) * 100)\n",
    "    print(\"Accuracy on test data with  k = \" + str(k) + \" : \", metrics.accuracy_score(Y_test, yhat) * 100)\n",
    "    print ()\n",
    "    k+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best KNN Accuracy is on K = 13 with K Accuracy of Almost 80% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Bernoulli Naive Bayes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0) \n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "gnb = BernoulliNB() \n",
    "gnb.fit(X_train, y_train) \n",
    "y_pred = gnb.predict(X_test) \n",
    "  \n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Bernoulli Naive Bayes model accuracy on test set     :\", metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Gaussian Naive Bayes\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0) \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB() \n",
    "gnb.fit(X_train, y_train) \n",
    "y_pred = gnb.predict(X_test)   \n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Gaussian Naive Bayes model accuracy on test set     :\", metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes is giving high accuracy among bernoulli and gaussian of 78%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Correlation Matrix to see if some features are dominating on other features and eradicating uselesss features\n",
    "\n",
    "plt.subplots(figsize=(10, 10))\n",
    "plt.title('Correlation Matrix')\n",
    "sns.heatmap(Feature.astype(float).corr(), square=True, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are no conclusive features which are directly correlated so we can continue with all the features for X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hepatitis Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Hepatitis Dataset\n",
    "\n",
    "hepatitis_df = pd.read_csv(\"Datasets/hepatitis-data.txt\",delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing first 5 rows\n",
    "\n",
    "hepatitis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute information from hepatitus-description.txt:\n",
    "     1. Class: DIE, LIVE\n",
    "     2. AGE: 10, 20, 30, 40, 50, 60, 70, 80\n",
    "     3. SEX: male, female\n",
    "     4. STEROID: no, yes\n",
    "     5. ANTIVIRALS: no, yes\n",
    "     6. FATIGUE: no, yes\n",
    "     7. MALAISE: no, yes\n",
    "     8. ANOREXIA: no, yes\n",
    "     9. LIVER BIG: no, yes\n",
    "    10. LIVER FIRM: no, yes\n",
    "    11. SPLEEN PALPABLE: no, yes\n",
    "    12. SPIDERS: no, yes\n",
    "    13. ASCITES: no, yes\n",
    "    14. VARICES: no, yes\n",
    "    15. BILIRUBIN: 0.39, 0.80, 1.20, 2.00, 3.00, 4.00\n",
    "        -- see the note below\n",
    "    16. ALK PHOSPHATE: 33, 80, 120, 160, 200, 250\n",
    "    17. SGOT: 13, 100, 200, 300, 400, 500, \n",
    "    18. ALBUMIN: 2.1, 3.0, 3.8, 4.5, 5.0, 6.0\n",
    "    19. PROTIME: 10, 20, 30, 40, 50, 60, 70, 80, 90\n",
    "    20. HISTOLOGY: no, yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving Column Names Present in Dataset\n",
    "\n",
    "hepatitis_df.columns = [\n",
    "                        'Class',\n",
    "                        'AGE',\n",
    "                        'SEX',\n",
    "                        'STEROID',\n",
    "                        'ANTIVIRALS',\n",
    "                        'FATIGUE',\n",
    "                        'MALAISE',\n",
    "                        'ANOREXIA',\n",
    "                        'LIVER BIG',\n",
    "                        'LIVER FIRM',\n",
    "                        'SPLEEN PALPABLE',\n",
    "                        'SPIDERS','ASCITES',\n",
    "                        'VARICES','BILIRUBIN',\n",
    "                        'ALK PHOSPHATE','SGOT',\n",
    "                        'ALBUMIN','PROTIME',\n",
    "                        'HISTOLOGY'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising dataset with column names\n",
    "hepatitis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last 5 rows of dataset\n",
    "\n",
    "hepatitis_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of dataset\n",
    "\n",
    "hepatitis_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replcaing the '?' with nan values\n",
    "\n",
    "hepatitis_df.replace(\"?\", np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the output label count\n",
    "\n",
    "hepatitis_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of null rows of dataset\n",
    "\n",
    "hepatitis_df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics of dataset\n",
    "\n",
    "hepatitis_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data types of dataframe column because less column shows in summary statistics\n",
    "\n",
    "hepatitis_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute information from hepatitus-description.txt:\n",
    "     1. Class: DIE, LIVE\n",
    "     2. AGE: 10, 20, 30, 40, 50, 60, 70, 80\n",
    "     3. SEX: male, female\n",
    "     4. STEROID: no, yes\n",
    "     5. ANTIVIRALS: no, yes\n",
    "     6. FATIGUE: no, yes\n",
    "     7. MALAISE: no, yes\n",
    "     8. ANOREXIA: no, yes\n",
    "     9. LIVER BIG: no, yes\n",
    "    10. LIVER FIRM: no, yes\n",
    "    11. SPLEEN PALPABLE: no, yes\n",
    "    12. SPIDERS: no, yes\n",
    "    13. ASCITES: no, yes\n",
    "    14. VARICES: no, yes\n",
    "    15. BILIRUBIN: 0.39, 0.80, 1.20, 2.00, 3.00, 4.00\n",
    "        -- see the note below\n",
    "    16. ALK PHOSPHATE: 33, 80, 120, 160, 200, 250\n",
    "    17. SGOT: 13, 100, 200, 300, 400, 500, \n",
    "    18. ALBUMIN: 2.1, 3.0, 3.8, 4.5, 5.0, 6.0\n",
    "    19. PROTIME: 10, 20, 30, 40, 50, 60, 70, 80, 90\n",
    "    20. HISTOLOGY: no, yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the Column Names\n",
    "\n",
    "hepatitis_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all the column which are numeric and provided info in description txt file so we can change into float values\n",
    "\n",
    "numColumns = ['AGE','BILIRUBIN','ALK PHOSPHATE','SGOT','ALBUMIN','PROTIME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting string columns into float values\n",
    "\n",
    "hepatitis_df[\"BILIRUBIN\"] = hepatitis_df[\"BILIRUBIN\"].astype(float)\n",
    "hepatitis_df[\"BILIRUBIN\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting string columns into float values\n",
    "\n",
    "hepatitis_df[\"ALK PHOSPHATE\"] = hepatitis_df[\"ALK PHOSPHATE\"].astype(float)\n",
    "hepatitis_df[\"ALK PHOSPHATE\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting string columns into float values\n",
    "\n",
    "hepatitis_df[\"SGOT\"] = hepatitis_df[\"SGOT\"].astype(float)\n",
    "hepatitis_df[\"SGOT\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting string columns into float values\n",
    "\n",
    "hepatitis_df[\"ALBUMIN\"] = hepatitis_df[\"ALBUMIN\"].astype(float)\n",
    "hepatitis_df[\"ALBUMIN\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting string columns into float values\n",
    "\n",
    "hepatitis_df[\"PROTIME\"] = hepatitis_df[\"PROTIME\"].astype(float)\n",
    "hepatitis_df[\"PROTIME\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the summary Statistics again to see if we are getting all the column now\n",
    "\n",
    "hepatitis_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the sum of all null values of particular column\n",
    "\n",
    "hepatitis_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Missing values with mean of the columns which have alot of nan values\n",
    "\n",
    "hepatitis_df['BILIRUBIN'] = hepatitis_df['BILIRUBIN'].fillna(hepatitis_df['BILIRUBIN'].mean())\n",
    "hepatitis_df['BILIRUBIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Missing values with mean of the columns which have alot of nan values\n",
    "\n",
    "hepatitis_df['ALK PHOSPHATE'] = hepatitis_df['ALK PHOSPHATE'].fillna(hepatitis_df['ALK PHOSPHATE'].mean())\n",
    "hepatitis_df['ALK PHOSPHATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Missing values with mean of the columns which have alot of nan values\n",
    "\n",
    "hepatitis_df['SGOT'] = hepatitis_df['SGOT'].fillna(hepatitis_df['SGOT'].mean())\n",
    "hepatitis_df['SGOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Missing values with mean of the columns which have alot of nan values\n",
    "\n",
    "hepatitis_df['ALBUMIN'] = hepatitis_df['ALBUMIN'].fillna(hepatitis_df['ALBUMIN'].mean())\n",
    "hepatitis_df['ALBUMIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Missing values with mean of the columns which have alot of nan values\n",
    "\n",
    "hepatitis_df['PROTIME'] = hepatitis_df['PROTIME'].fillna(hepatitis_df['PROTIME'].mean())\n",
    "hepatitis_df['PROTIME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking again now how many columns are still have nan values. There are stirng columns\n",
    "\n",
    "hepatitis_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all the categorical column values with mode imputation\n",
    "\n",
    "hepatitis_df = hepatitis_df.fillna(hepatitis_df.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values again. Now dataset is preety clean\n",
    "\n",
    "hepatitis_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types of each column\n",
    "\n",
    "hepatitis_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting whole dataset into float\n",
    "\n",
    "hepatitis_df = hepatitis_df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varify if dataset is fully converted\n",
    "\n",
    "hepatitis_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting all the features initially for our X\n",
    "\n",
    "Feature = hepatitis_df.iloc[:, [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Feature\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalization for getting better and faster results\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the output value (y)\n",
    "\n",
    "output = hepatitis_df.iloc[:, [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = output\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the label into int value\n",
    "\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y['Class'].values\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying KNN to Hepatitis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.25, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying KNN on differnt values of K\n",
    "\n",
    "k = 1\n",
    "for i in range (20):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k).fit(X_train,Y_train)\n",
    "    yhat = knn.predict(X_test)\n",
    "    print (\"KNN with k = \" + str(k))\n",
    "    print(\"Accuracy on train data with k = \" + str (k) + \" : \", metrics.accuracy_score(Y_train,knn.predict(X_train)) * 100)\n",
    "    print(\"Accuracy on test data with  k = \" + str(k) + \" : \", metrics.accuracy_score(Y_test, yhat) * 100)\n",
    "    print ()\n",
    "    k+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The best accuracy is on K = 3 with Train Accuracy = 93.04% & Test Accuracy = 87.17%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Naive Bayes on Hepatitus Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernaouli Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "gnb = BernoulliNB() \n",
    "gnb.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gnb.predict(X_test) \n",
    "y_trainPred = gnb.predict(X_train) \n",
    "  \n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Bernoulli Naive Bayes model accuracy on test set     :\", metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0) \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB() \n",
    "gnb.fit(X_train, y_train) \n",
    "y_pred = gnb.predict(X_test) \n",
    "y_trainPred = gnb.predict(X_train) \n",
    "\n",
    "\n",
    "print(\"Gaussian Naive Bayes model accuracy on test set     :\", metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The best accuracy is found on Bernoulli Naive Bayes with Test Acc = 83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Correlation Matrix to see if some features are dominating on other features and eradicating uselesss features\n",
    "\n",
    "plt.subplots(figsize=(15, 15))\n",
    "plt.title('Correlation Matrix')\n",
    "sns.heatmap(Feature.astype(float).corr(), square=True, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Problematic Features with negative correlation values i.e col# 2, 13, 14, 16, 19\n",
    "\n",
    "Feature = hepatitis_df.iloc[:, [1,3,4,5,6,7,8,9,10,11,12,15,17,18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting our new features \n",
    "\n",
    "X = Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying normalization\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data again\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.25, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying KNN on differnt values of K\n",
    "\n",
    "k = 1\n",
    "for i in range (20):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k).fit(X_train,Y_train)\n",
    "    yhat = knn.predict(X_test)\n",
    "    print (\"KNN with k = \" + str(k))\n",
    "    print(\"Accuracy on train data with k = \" + str (k) + \" : \", metrics.accuracy_score(Y_train,knn.predict(X_train)) * 100)\n",
    "    print(\"Accuracy on test data with  k = \" + str(k) + \" : \", metrics.accuracy_score(Y_test, yhat) * 100)\n",
    "    print ()\n",
    "    k+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we are getting maximum accuracy of 92% but model is overfitting slightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix After Feature Improvement\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "matrix = classification_report(Y_test,yhat)\n",
    "print('Classification report : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liver-Disorder Dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading dataset\n",
    "\n",
    "liver_df = pd.read_csv(\"Datasets/liver_disorder_data.txt\",delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Attribute information:\n",
    "   1. mcv\tmean corpuscular volume\n",
    "   2. alkphos\talkaline phosphotase\n",
    "   3. sgpt\talamine aminotransferase\n",
    "   4. sgot \taspartate aminotransferase\n",
    "   5. gammagt\tgamma-glutamyl transpeptidase\n",
    "   6. drinks\tnumber of half-pint equivalents of alcoholic beverages drunk per day\n",
    "   7. selector  field used to split data into two sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving the column names as given in text file\n",
    "\n",
    "liver_df.columns = [\n",
    "                        'mcv',\n",
    "                        'alkphos',\n",
    "                        'sgpt',\n",
    "                        'sgot',\n",
    "                        'gammagt',\n",
    "                        'drinks',\n",
    "                        'selector'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing ? with nan\n",
    "\n",
    "liver_df.replace(\"?\", np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_df = liver_df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_df = liver_df.fillna(liver_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_df.isin({0.0}).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_df['selector'] = liver_df['selector'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature = liver_df.iloc[:, [0,1,2,3,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = liver_df.iloc[:, [0,1,2,3,4,5]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = liver_df['selector'].values\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.30, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "for i in range (20):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k).fit(X_train,Y_train)\n",
    "    yhat = knn.predict(X_test)\n",
    "    print (\"KNN With k = \" + str(k))\n",
    "    print(\"Accuracy on train data with k = \" + str (k) + \" : \", metrics.accuracy_score(Y_train,knn.predict(X_train)) * 100)\n",
    "    print(\"Accuracy on test data with  k = \" + str(k) + \" : \", metrics.accuracy_score(Y_test, yhat) * 100)\n",
    "    print ()\n",
    "    k+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Before Feature Improvement\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "matrix = classification_report(Y_test,yhat)\n",
    "print('Classification report : \\n',matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best accuracy is on K = 19 with Accuracy = 70.19%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0) \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB() \n",
    "gnb.fit(X_train, y_train) \n",
    "y_pred = gnb.predict(X_test)   \n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Gaussian Naive Bayes model accuracy on test set     :\", metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0) \n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "gnb = BernoulliNB() \n",
    "gnb.fit(X_train, y_train) \n",
    "y_pred = gnb.predict(X_test)   \n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Bernoulli Naive Bayes model accuracy on test set     :\", metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10, 10))\n",
    "plt.title('Correlation Matrix')\n",
    "sns.heatmap(Feature.astype(float).corr(), square=True, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected those features which are highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting sgpt, sgot, gammagt and drinks due to highly correlated results\n",
    "\n",
    "X = liver_df.iloc[:, [2,3,4,5]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying normalization\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.30, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predd = []\n",
    "k = 1\n",
    "for i in range (20):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k).fit(X_train,Y_train)\n",
    "    yhat = knn.predict(X_test)\n",
    "    print (\"KNN With k = \" + str(k))\n",
    "    print(\"Accuracy on train data with k = \" + str (k) + \" : \", metrics.accuracy_score(Y_train,knn.predict(X_train)) * 100)\n",
    "    print(\"Accuracy on test data with  k = \" + str(k) + \" : \", metrics.accuracy_score(Y_test, yhat) * 100)\n",
    "    print ()\n",
    "    k+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix After Feature Improvement\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "matrix = classification_report(Y_test,yhat)\n",
    "print('Classification report : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting confusion Matrix\n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:  \n",
    "            TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "            FP += 1\n",
    "        if y_actual[i]==y_hat[i]==2:\n",
    "            TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "            FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)\n",
    "\n",
    "tp, fp, tn, fn = perf_measure(Y_test, yhat)\n",
    "\n",
    "print (\"True Positive  : \" + str(tp))\n",
    "print (\"False Positive : \" + str(fp))\n",
    "print (\"True Nagative  : \"  + str(tn))\n",
    "print (\"False Negative : \" + str(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validaiton With Bin Size of 5 and tested on different sizes\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "k = 1\n",
    "\n",
    "for i in range (20):\n",
    "    print (\"K = \" + str(k))\n",
    "    knn_cv = KNeighborsClassifier(n_neighbors = k)\n",
    "\n",
    "    cv_scores = cross_val_score(knn_cv, X, y, cv = 5)\n",
    "    print(cv_scores)\n",
    "    print('Cross Validation Scores Mean:{}'.format(np.mean(cv_scores)))\n",
    "    k = k + 1\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lung-Cancer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lungCancer_df = pd.read_csv(\"Datasets/lung_cancer_data.txt\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lungCancer_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lungCancer_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No information about columns are given so col1, col2 .. names are assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving column Values\n",
    "\n",
    "lungCancer_df.columns = [\n",
    "                        'col1','col2','col3','col4','col5','col6','col7','col8','col9','col10',\n",
    "                        'col11','col12','col13','col14','col15','col16','col17','col18','col19','col20',\n",
    "                        'col21','col22','col23','col24','col52','col26','col27','col28','col29','col30',\n",
    "                        'col31','col32','col33','col34','col35','col36','col37','col38','col39','col40',\n",
    "                        'col41','col42','col43','col44','col45','col46','col47','col48','col49','col50',\n",
    "                        'col51','col52','col53','col54','col55','col56','col57'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lungCancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lungCancer_df.replace(\"?\", np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lungCancer_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lungCancer_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lungCancer_df = lungCancer_df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all null values\n",
    "\n",
    "lungCancer_df['col5'] = lungCancer_df.fillna(lungCancer_df['col5'].mode())\n",
    "lungCancer_df['col2'] = lungCancer_df.fillna(lungCancer_df['col2'].mode())\n",
    "lungCancer_df['col6'] = lungCancer_df.fillna(lungCancer_df['col6'].mode())\n",
    "lungCancer_df['col12'] = lungCancer_df.fillna(lungCancer_df['col12'].mode())\n",
    "lungCancer_df['col29'] = lungCancer_df.fillna(lungCancer_df['col29'].mode())\n",
    "lungCancer_df['col30'] = lungCancer_df.fillna(lungCancer_df['col30'].mode())\n",
    "lungCancer_df['col39'] = lungCancer_df.fillna(lungCancer_df['col39'].mode())\n",
    "lungCancer_df['col42'] = lungCancer_df.fillna(lungCancer_df['col42'].mode())\n",
    "lungCancer_df['col48'] = lungCancer_df.fillna(lungCancer_df['col48'].mode())\n",
    "lungCancer_df['col51'] = lungCancer_df.fillna(lungCancer_df['col51'].mode())\n",
    "lungCancer_df['col53'] = lungCancer_df.fillna(lungCancer_df['col53'].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lungCancer_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting all features initially and then select only those which are good\n",
    "\n",
    "Feature = lungCancer_df.loc[:, lungCancer_df.columns != 'col57']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lungCancer_df['col57'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.35, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN with different k values\n",
    "\n",
    "k = 1\n",
    "for i in range (20):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k).fit(X_train,Y_train)\n",
    "    yhat = knn.predict(X_test)\n",
    "    print (\"KNN With k = \" + str(k))\n",
    "    print(\"Accuracy on train data with k = \" + str (k) + \" : \", metrics.accuracy_score(Y_train,knn.predict(X_train)) * 100)\n",
    "    print(\"Accuracy on test data with  k = \" + str(k) + \" : \", metrics.accuracy_score(Y_test, yhat) * 100)\n",
    "    print ()\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN is giving high accuracy of 72%  which is very biased because we have only 31 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=0) \n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "gnb = BernoulliNB() \n",
    "gnb.fit(X_train, y_train) \n",
    "y_pred = gnb.predict(X_test)   \n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Bernoulli Naive Bayes model accuracy on test set     :\", metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=0) \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB() \n",
    "gnb.fit(X_train, y_train) \n",
    "y_pred = gnb.predict(X_test)   \n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Gaussian Naive Bayes model accuracy on test set     :\", metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "\n",
    "plt.subplots(figsize=(30, 30))\n",
    "plt.title('Correlation Matrix')\n",
    "sns.heatmap(Feature.astype(float).corr(), square=True, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is no Conclusive Relation among different columns so we can go with all features selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
